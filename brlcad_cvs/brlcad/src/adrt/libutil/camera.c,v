head	1.28;
access;
symbols
	rel-7-10-4:1.27
	STABLE:1.27.0.2
	rel-7-10-2:1.25
	rel-7-10-0:1.25
	rel-7-8-4:1.17
	rel-7-8-2:1.17
	rel-7-8-0:1.17
	trimnurbs-branch:1.17.0.2
	help:1.17
	temp_tag:1.16
	bobWinPort-20051223-freeze:1.7
	postmerge-20051223-bobWinPort:1.16
	premerge-20051223-bobWinPort:1.16
	rel-7-6-6:1.16
	rel-7-6-4:1.16
	rel-7-6-2:1.7
	rel-7-6-branch:1.7.0.4
	rel-7-6-0:1.7
	rel-7-4-2:1.6
	rel-7-4-branch:1.6.0.2
	bobWinPort:1.7.0.2
	rel-7-4-0:1.6;
locks; strict;
comment	@ * @;


1.28
date	2007.12.06.18.23.46;	author erikgreenwald;	state Exp;
branches;
next	1.27;

1.27
date	2007.09.10.19.38.27;	author erikgreenwald;	state Exp;
branches;
next	1.26;

1.26
date	2007.08.30.19.11.30;	author brlcad;	state Exp;
branches;
next	1.25;

1.25
date	2007.03.20.20.05.08;	author brlcad;	state Exp;
branches;
next	1.24;

1.24
date	2007.02.08.06.49.19;	author brlcad;	state Exp;
branches;
next	1.23;

1.23
date	2007.02.02.19.46.35;	author erikgreenwald;	state Exp;
branches;
next	1.22;

1.22
date	2007.01.27.01.41.30;	author brlcad;	state Exp;
branches;
next	1.21;

1.21
date	2007.01.23.01.13.22;	author brlcad;	state Exp;
branches;
next	1.20;

1.20
date	2007.01.21.00.51.05;	author brlcad;	state Exp;
branches;
next	1.19;

1.19
date	2007.01.20.14.36.41;	author brlcad;	state Exp;
branches;
next	1.18;

1.18
date	2007.01.18.22.17.57;	author erikgreenwald;	state Exp;
branches;
next	1.17;

1.17
date	2006.01.18.06.46.12;	author brlcad;	state Exp;
branches;
next	1.16;

1.16
date	2005.10.30.21.58.57;	author brlcad;	state Exp;
branches;
next	1.15;

1.15
date	2005.10.23.04.44.28;	author brlcad;	state Exp;
branches;
next	1.14;

1.14
date	2005.09.21.16.16.16;	author twingy;	state Exp;
branches;
next	1.13;

1.13
date	2005.09.21.02.15.02;	author twingy;	state Exp;
branches;
next	1.12;

1.12
date	2005.09.20.19.27.55;	author twingy;	state Exp;
branches;
next	1.11;

1.11
date	2005.09.20.19.05.35;	author twingy;	state Exp;
branches;
next	1.10;

1.10
date	2005.09.12.18.13.47;	author twingy;	state Exp;
branches;
next	1.9;

1.9
date	2005.09.10.19.16.29;	author twingy;	state Exp;
branches;
next	1.8;

1.8
date	2005.09.09.22.06.26;	author twingy;	state Exp;
branches;
next	1.7;

1.7
date	2005.08.15.03.45.25;	author twingy;	state Exp;
branches
	1.7.4.1;
next	1.6;

1.6
date	2005.07.11.22.33.45;	author brlcad;	state Exp;
branches;
next	1.5;

1.5
date	2005.07.02.19.54.59;	author twingy;	state Exp;
branches;
next	1.4;

1.4
date	2005.06.21.05.36.29;	author twingy;	state Exp;
branches;
next	1.3;

1.3
date	2005.06.18.01.30.04;	author twingy;	state Exp;
branches;
next	1.2;

1.2
date	2005.06.17.21.41.00;	author erikgreenwald;	state Exp;
branches;
next	1.1;

1.1
date	2005.06.17.15.09.28;	author lbutler;	state Exp;
branches;
next	;

1.7.4.1
date	2005.11.13.13.46.12;	author brlcad;	state Exp;
branches;
next	;


desc
@@


1.28
log
@use bu_avail_cpu()s instead of the FreeBSD-only get_procs() version
@
text
@/*                     C A M E R A . C
 * BRL-CAD / ADRT
 *
 * Copyright (c) 2002-2007 United States Government as represented by
 * the U.S. Army Research Laboratory.
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public License
 * version 2.1 as published by the Free Software Foundation.
 *
 * This library is distributed in the hope that it will be useful, but
 * WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this file; see the file named COPYING for more
 * information.
 */
/** @@file camera.c
 *
 *  Comments -
 *      Utilities Library - Camera
 *
 *  Author -
 *      Justin L. Shumaker
 *
 *  Source -
 *      The U. S. Army Research Laboratory
 *      Aberdeen Proving Ground, Maryland  21005-5068  USA
 *
 * $Id: camera.c,v 1.27 2007/09/10 19:38:27 erikgreenwald Exp $
 */

#include "camera.h"
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/time.h>
#include <time.h>
#include <unistd.h>

#include "common.h"
#include "image.h"
#include "umath.h"

#include "bu.h"

#ifdef HAVE_SYS_SYSINFO_H
#  include <sys/sysinfo.h>
#elif defined(HAVE_SYS_SYSCTL_H)
#  include <sys/sysctl.h>
#endif

pthread_t *util_tlist;

void* util_camera_render_thread(void *ptr);

void util_camera_init(util_camera_t *camera, int threads) {
  camera->view_num = 0;
  camera->view_list = NULL;

  /* The camera will use a thread for every cpu the machine has. */
  camera->thread_num = threads ? threads : bu_avail_cpus();

  if(camera->thread_num > 1) {
    util_tlist = (pthread_t *)malloc(sizeof(pthread_t) * camera->thread_num);
    if (!util_tlist) {
	perror("malloc");
	exit(1);
    }
    if (!util_tlist) {
	perror("util_tlist");
	exit(1);
    }
  }
}


void util_camera_free(util_camera_t *camera) {
  if(camera->thread_num > 1)
    free(util_tlist);
}


void util_camera_prep(util_camera_t *camera, common_db_t *db) {
  TIE_3		dof_topl, dof_botl, dof_topr, fov_topl, fov_botl, fov_topr;
  TIE_3		temp, dof_look, dof_up, dof_side, fov_look, fov_up, fov_side, step_x, step_y;
  tfloat	sfov, cfov, sdof, cdof, aspect, angle, mag;
  int		i, n;


  /* Generate an aspect ratio coefficient */
  aspect = (tfloat)db->env.img_vw / (tfloat)db->env.img_vh;

  /* Free camera view list if already allocated */
  if(camera->view_list)
    free(camera->view_list);

  /* If there is no depth of field then just generate the standard look vector */
  if(camera->dof == 0.0) {
    camera->view_num = 1;
    camera->view_list = (util_camera_view_t *)malloc(sizeof(util_camera_view_t) * camera->view_num);
    if (!camera->view_list) {
	perror("view_list");
	exit(1);
    }

    /* Generate unitized look vector */
    MATH_VEC_SUB(fov_look, camera->focus, camera->pos);
    MATH_VEC_UNITIZE(fov_look);

    /* Generate standard up vector */
    fov_up.v[0] = 0;
    fov_up.v[1] = 0;
    fov_up.v[2] = 1;

    /* Make unitized up vector perpendicular to look vector */
    temp = fov_look;
    MATH_VEC_DOT(angle, fov_up, temp);
    MATH_VEC_MUL_SCALAR(temp, temp, angle);
    MATH_VEC_SUB(fov_up, fov_up, temp);
    MATH_VEC_UNITIZE(fov_up);

    /* Generate a temporary side vector */
    MATH_VEC_CROSS(fov_side, fov_up, fov_look);

    /* Apply tilt to up vector - negate angle to make positive angles clockwise */
    sfov = sin(-camera->tilt * MATH_PI * MATH_1DIV180);
    cfov = cos(-camera->tilt * MATH_PI * MATH_1DIV180);
    MATH_VEC_MUL_SCALAR(fov_up, fov_up, cfov);
    MATH_VEC_MUL_SCALAR(fov_side, fov_side, sfov);
    MATH_VEC_ADD(fov_up, fov_up, fov_side);

    /* Create final side vector */
    MATH_VEC_CROSS(fov_side, fov_up, fov_look);

    /* Compute sine and cosine terms for field of view */
    sfov = sin(camera->fov*MATH_PI * MATH_1DIV180);
    cfov = cos(camera->fov*MATH_PI * MATH_1DIV180);


    /* Up, Look, and Side vectors are complete, generate Top Left reference vector */
    fov_topl.v[0] = sfov*fov_up.v[0] + aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
    fov_topl.v[1] = sfov*fov_up.v[1] + aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
    fov_topl.v[2] = sfov*fov_up.v[2] + aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

    fov_topr.v[0] = sfov*fov_up.v[0] - aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
    fov_topr.v[1] = sfov*fov_up.v[1] - aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
    fov_topr.v[2] = sfov*fov_up.v[2] - aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

    fov_botl.v[0] = -sfov*fov_up.v[0] + aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
    fov_botl.v[1] = -sfov*fov_up.v[1] + aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
    fov_botl.v[2] = -sfov*fov_up.v[2] + aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

    MATH_VEC_UNITIZE(fov_topl);
    MATH_VEC_UNITIZE(fov_botl);
    MATH_VEC_UNITIZE(fov_topr);

    /* Store Camera Position */
    camera->view_list[0].pos = camera->pos;

    /* Store the top left vector */
    camera->view_list[0].top_l = fov_topl;

    /* Generate stepx and stepy vectors for sampling each pixel */
    MATH_VEC_SUB(camera->view_list[0].step_x, fov_topr, fov_topl);
    MATH_VEC_SUB(camera->view_list[0].step_y, fov_botl, fov_topl);

    /* Divide stepx and stepy by the number of pixels */
    MATH_VEC_MUL_SCALAR(camera->view_list[0].step_x, camera->view_list[0].step_x, 1.0 / db->env.img_vw);
    MATH_VEC_MUL_SCALAR(camera->view_list[0].step_y, camera->view_list[0].step_y, 1.0 / db->env.img_vh);
    return;
  }

  /*
  * GENERATE DEPTH OF VIEW CAMERA DATA
  */

  /* Generate unitized look vector */
  MATH_VEC_SUB(dof_look, camera->focus, camera->pos);
  MATH_VEC_UNITIZE(dof_look);

  /* Generate standard up vector */
  dof_up.v[0] = 0;
  dof_up.v[1] = 0;
  dof_up.v[2] = 1;

  /* Make unitized up vector perpendicular to look vector */
  temp = dof_look;
  MATH_VEC_DOT(angle, dof_up, temp);
  MATH_VEC_MUL_SCALAR(temp, temp, angle);
  MATH_VEC_SUB(dof_up, dof_up, temp);
  MATH_VEC_UNITIZE(dof_up);

  /* Generate a temporary side vector */
  MATH_VEC_CROSS(dof_side, dof_up, dof_look);

  /* Apply tilt to up vector - negate angle to make positive angles clockwise */
  sdof = sin(-camera->tilt * MATH_PI * MATH_1DIV180);
  cdof = cos(-camera->tilt * MATH_PI * MATH_1DIV180);
  MATH_VEC_MUL_SCALAR(dof_up, dof_up, cdof);
  MATH_VEC_MUL_SCALAR(dof_side, dof_side, sdof);
  MATH_VEC_ADD(dof_up, dof_up, dof_side);

  /* Create final side vector */
  MATH_VEC_CROSS(dof_side, dof_up, dof_look);

  /*
  * Generage a camera position, top left vector, and step vectors for each DOF sample
  */

  /* Obtain magnitude of reverse look vector */
  MATH_VEC_SUB(dof_look, camera->pos, camera->focus);
  MATH_VEC_MAG(mag, dof_look);
  MATH_VEC_UNITIZE(dof_look);


  /* Compute sine and cosine terms for field of view */
  sdof = sin(camera->dof*MATH_PI * MATH_1DIV180);
  cdof = cos(camera->dof*MATH_PI * MATH_1DIV180);


  /* Up, Look, and Side vectors are complete, generate Top Left reference vector */
  dof_topl.v[0] = sdof*dof_up.v[0] + sdof*dof_side.v[0] + cdof*dof_look.v[0];
  dof_topl.v[1] = sdof*dof_up.v[1] + sdof*dof_side.v[1] + cdof*dof_look.v[1];
  dof_topl.v[2] = sdof*dof_up.v[2] + sdof*dof_side.v[2] + cdof*dof_look.v[2];

  dof_topr.v[0] = sdof*dof_up.v[0] - sdof*dof_side.v[0] + cdof*dof_look.v[0];
  dof_topr.v[1] = sdof*dof_up.v[1] - sdof*dof_side.v[1] + cdof*dof_look.v[1];
  dof_topr.v[2] = sdof*dof_up.v[2] - sdof*dof_side.v[2] + cdof*dof_look.v[2];

  dof_botl.v[0] = -sdof*dof_up.v[0] + sdof*dof_side.v[0] + cdof*dof_look.v[0];
  dof_botl.v[1] = -sdof*dof_up.v[1] + sdof*dof_side.v[1] + cdof*dof_look.v[1];
  dof_botl.v[2] = -sdof*dof_up.v[2] + sdof*dof_side.v[2] + cdof*dof_look.v[2];

  MATH_VEC_UNITIZE(dof_topl);
  MATH_VEC_UNITIZE(dof_botl);
  MATH_VEC_UNITIZE(dof_topr);

  MATH_VEC_SUB(step_x, dof_topr, dof_topl);
  MATH_VEC_SUB(step_y, dof_botl, dof_topl);

  /* Generate camera positions for depth of field */
  camera->view_num = UTIL_CAMERA_DOF_SAMPLES*UTIL_CAMERA_DOF_SAMPLES;
  camera->view_list = (util_camera_view_t *)malloc(sizeof(util_camera_view_t) * camera->view_num);
  if (!camera->view_list) {
      perror("view_list");
      exit(1);
  }

  for(i = 0; i < UTIL_CAMERA_DOF_SAMPLES; i++) {
    for(n = 0; n < UTIL_CAMERA_DOF_SAMPLES; n++) {
      /* Generate virtual camera position for this depth of field sample */
      MATH_VEC_MUL_SCALAR(temp, step_x, ((tfloat)i/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
      MATH_VEC_ADD(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, dof_topl, temp);
      MATH_VEC_MUL_SCALAR(temp, step_y, ((tfloat)n/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
      MATH_VEC_ADD(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, temp);
      MATH_VEC_UNITIZE(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos);
      MATH_VEC_MUL_SCALAR(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, mag);
      MATH_VEC_ADD(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->focus);

      /* Generate unitized look vector */
      MATH_VEC_SUB(fov_look, camera->focus, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos);
      MATH_VEC_UNITIZE(fov_look);

      /* Generate standard up vector */
      fov_up.v[0] = 0;
      fov_up.v[1] = 0;
      fov_up.v[2] = 1;

      /* Make unitized up vector perpendicular to look vector */
      temp = fov_look;
      MATH_VEC_DOT(angle, fov_up, temp);
      MATH_VEC_MUL_SCALAR(temp, temp, angle);
      MATH_VEC_SUB(fov_up, fov_up, temp);
      MATH_VEC_UNITIZE(fov_up);

      /* Generate a temporary side vector */
      MATH_VEC_CROSS(fov_side, fov_up, fov_look);

      /* Apply tilt to up vector - negate angle to make positive angles clockwise */
      sfov = sin(-camera->tilt * MATH_PI * MATH_1DIV180);
      cfov = cos(-camera->tilt * MATH_PI * MATH_1DIV180);
      MATH_VEC_MUL_SCALAR(fov_up, fov_up, cfov);
      MATH_VEC_MUL_SCALAR(fov_side, fov_side, sfov);
      MATH_VEC_ADD(fov_up, fov_up, fov_side);

      /* Create final side vector */
      MATH_VEC_CROSS(fov_side, fov_up, fov_look);

      /* Compute sine and cosine terms for field of view */
      sfov = sin(camera->fov*MATH_PI * MATH_1DIV180);
      cfov = cos(camera->fov*MATH_PI * MATH_1DIV180);


      /* Up, Look, and Side vectors are complete, generate Top Left reference vector */
      fov_topl.v[0] = sfov*fov_up.v[0] + aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
      fov_topl.v[1] = sfov*fov_up.v[1] + aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
      fov_topl.v[2] = sfov*fov_up.v[2] + aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

      fov_topr.v[0] = sfov*fov_up.v[0] - aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
      fov_topr.v[1] = sfov*fov_up.v[1] - aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
      fov_topr.v[2] = sfov*fov_up.v[2] - aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

      fov_botl.v[0] = -sfov*fov_up.v[0] + aspect*sfov*fov_side.v[0] + cfov*fov_look.v[0];
      fov_botl.v[1] = -sfov*fov_up.v[1] + aspect*sfov*fov_side.v[1] + cfov*fov_look.v[1];
      fov_botl.v[2] = -sfov*fov_up.v[2] + aspect*sfov*fov_side.v[2] + cfov*fov_look.v[2];

      MATH_VEC_UNITIZE(fov_topl);
      MATH_VEC_UNITIZE(fov_botl);
      MATH_VEC_UNITIZE(fov_topr);

      /* Store the top left vector */
      camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].top_l = fov_topl;

      /* Generate stepx and stepy vectors for sampling each pixel */
      MATH_VEC_SUB(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, fov_topr, fov_topl);
      MATH_VEC_SUB(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, fov_botl, fov_topl);

      /* Divide stepx and stepy by the number of pixels */
      MATH_VEC_MUL_SCALAR(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, 1.0 / db->env.img_vw);
      MATH_VEC_MUL_SCALAR(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, 1.0 / db->env.img_vh);
    }
  }
}


void* util_camera_render_thread(void *ptr) {
  util_camera_thread_data_t *td;
  int d, n, res_ind, scanline, v_scanline;
  TIE_3 pixel, accum, v1, v2;
  tie_ray_t ray;
  tfloat view_inv;


  td = (util_camera_thread_data_t *)ptr;
  view_inv = 1.0 / td->camera->view_num;


  res_ind = 0;
  /*  for(i = td->work.orig_y; i < td->work.orig_y + td->work.size_y; i++) { */	/* row, vertical */
  while(1) {
    /* Determine if this scanline should be computed by this thread */
    pthread_mutex_lock(&td->mut);
    if(*td->scanline == td->work.size_y) {
      pthread_mutex_unlock(&td->mut);
      return(0);
    } else {
      scanline = *td->scanline;
      (*td->scanline)++;
    }
    pthread_mutex_unlock(&td->mut);

    v_scanline = scanline + td->work.orig_y;
    if(td->work.format == COMMON_BIT_DEPTH_24) {
      res_ind = 3*scanline*td->work.size_x;
    } else if(td->work.format == COMMON_BIT_DEPTH_128) {
      res_ind = 4*scanline*td->work.size_x;
    }


    /* optimization if there is no depth of field being applied */
    if(td->camera->view_num == 1) {
      MATH_VEC_MUL_SCALAR(v1, td->camera->view_list[0].step_y, v_scanline);
      MATH_VEC_ADD(v1, v1, td->camera->view_list[0].top_l);
    }


    /* scanline, horizontal, each pixel */
    for(n = td->work.orig_x; n < td->work.orig_x + td->work.size_x; n++) {

      /* depth of view samples */
      if(td->camera->view_num > 1) {
	MATH_VEC_SET(accum, 0, 0, 0);

	for(d = 0; d < td->camera->view_num; d++) {
	  MATH_VEC_MUL_SCALAR(ray.dir, td->camera->view_list[d].step_y, v_scanline);
	  MATH_VEC_ADD(ray.dir, ray.dir, td->camera->view_list[d].top_l);
	  MATH_VEC_MUL_SCALAR(v1, td->camera->view_list[d].step_x, n);
	  MATH_VEC_ADD(ray.dir, ray.dir, v1);

	  MATH_VEC_SET(pixel, 0, 0, 0);

	  ray.pos = td->camera->view_list[d].pos;
	  ray.depth = 0;
	  MATH_VEC_UNITIZE(ray.dir);

	  /* Compute pixel value using this ray */
	  td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);

	  MATH_VEC_ADD(accum, accum, pixel);
	}

	/* Find Mean value of all views */
	MATH_VEC_MUL_SCALAR(pixel, accum, view_inv);
      } else {
	MATH_VEC_MUL_SCALAR(v2, td->camera->view_list[0].step_x, n);
	MATH_VEC_ADD(ray.dir, v1, v2);

	MATH_VEC_SET(pixel, 0, 0, 0);

	ray.pos = td->camera->view_list[0].pos;
	ray.depth = 0;
	MATH_VEC_UNITIZE(ray.dir);

	/* Compute pixel value using this ray */
	td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
      }


      if(td->work.format == COMMON_BIT_DEPTH_24) {
	if(pixel.v[0] > 1) pixel.v[0] = 1;
	if(pixel.v[1] > 1) pixel.v[1] = 1;
	if(pixel.v[2] > 1) pixel.v[2] = 1;
	((char *)(td->res_buf))[res_ind+0] = (unsigned char)(255 * pixel.v[0]);
	((char *)(td->res_buf))[res_ind+1] = (unsigned char)(255 * pixel.v[1]);
	((char *)(td->res_buf))[res_ind+2] = (unsigned char)(255 * pixel.v[2]);
	res_ind += 3;
      } else if(td->work.format == COMMON_BIT_DEPTH_128) {
	tfloat alpha;

	alpha = 1.0;

	((tfloat *)(td->res_buf))[res_ind + 0] = pixel.v[0];
	((tfloat *)(td->res_buf))[res_ind + 1] = pixel.v[1];
	((tfloat *)(td->res_buf))[res_ind + 2] = pixel.v[2];
	((tfloat *)(td->res_buf))[res_ind + 3] = alpha;

	res_ind += 4;
      }
/*          printf("Pixel: [%d, %d, %d]\n", rgb[0], rgb[1], rgb[2]); */

    }
  }

  return(0);
}


void util_camera_render(util_camera_t *camera, common_db_t *db, tie_t *tie, void *data, unsigned int size, void **res_buf, unsigned int *res_len) {
  common_work_t work;
  util_camera_thread_data_t td;
  unsigned char *scan_map;
  TIE_3 vec;
  unsigned int i, scanline;


  /* Format incoming data into a work structure */
  memcpy(&work, data, sizeof(common_work_t));

  /* Flip bits if endian requires us to */
  if(tienet_endian) {
    tienet_flip(&work.orig_x, &work.orig_x, sizeof(short));
    tienet_flip(&work.orig_y, &work.orig_y, sizeof(short));
    tienet_flip(&work.size_x, &work.size_x, sizeof(short));
    tienet_flip(&work.size_y, &work.size_y, sizeof(short));
    tienet_flip(&work.format, &work.format, sizeof(short));
  }


  if(work.format == COMMON_BIT_DEPTH_24) {
    *res_len = 3 * work.size_x * work.size_y + sizeof(common_work_t);
  } else if(work.format == COMMON_BIT_DEPTH_128) {
    *res_len = 4 * sizeof(tfloat) * work.size_x * work.size_y + sizeof(common_work_t);
  }

  *res_buf = realloc(*res_buf, *res_len);
  memcpy(*res_buf, data, sizeof(common_work_t));

  td.tie = tie;
  td.camera = camera;
  td.db = db;
  td.work = work;
  td.res_buf = &((char *)*res_buf)[sizeof(common_work_t)];
  scanline = 0;
  td.scanline = &scanline;
  pthread_mutex_init(&td.mut, 0);

  /* Launch Render threads */
  if(camera->thread_num > 1) {
    for(i = 0; i < camera->thread_num; i++)
      pthread_create(&util_tlist[i], NULL, util_camera_render_thread, &td);
    for(i = 0; i < camera->thread_num; i++)
      pthread_join(util_tlist[i], NULL);
  } else {
    util_camera_render_thread(&td);
  }

  pthread_mutex_destroy(&td.mut);
}

/*
 * Local Variables:
 * mode: C
 * tab-width: 8
 * c-basic-offset: 4
 * indent-tabs-mode: t
 * End:
 * ex: shiftwidth=4 tabstop=8
 */
@


1.27
log
@should only be using common.h, not brlcad_config.h
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.26 2007/08/30 19:11:30 brlcad Exp $
d43 1
d48 2
a55 1

a57 24

int get_nprocs(void);


#ifndef HAVE_SYS_SYSINFO_H
#ifdef HAVE_SYS_SYSCTL_H
int get_nprocs() {
  int mib[2], maxproc;
  size_t len;

  mib[0] = CTL_HW;
  mib[1] = HW_NCPU;
  len = sizeof(maxproc);
  sysctl(mib, 2, &maxproc, &len, NULL, 0);
  return maxproc;
}
#else
int get_nprocs() {
  return 1;
}
#endif
#endif


a59 1

d65 1
a65 1
  camera->thread_num = threads ? threads : get_nprocs();
@


1.26
log
@TFLOAT changed to tfloat.  also quell a few warnings/bugs related to passing the wrong TIE_3 pointer type.
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.25 2007/03/20 20:05:08 brlcad Exp $
d43 1
a43 1
#include "brlcad_config.h"
@


1.25
log
@since adrt uses malloc, add checks on use for a null return value.  this probably would be a good reason to being associating with libbu.. (this fixes sf bug 1680679 - Check return codes everywhere; submitted by Markus Elfring (elfring))
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.24 2007/02/08 06:49:19 brlcad Exp $
d113 1
a113 1
  TFLOAT	sfov, cfov, sdof, cdof, aspect, angle, mag;
d118 1
a118 1
  aspect = (TFLOAT)db->env.img_vw / (TFLOAT)db->env.img_vh;
d279 1
a279 1
      MATH_VEC_MUL_SCALAR(temp, step_x, ((TFLOAT)i/(TFLOAT)(UTIL_CAMERA_DOF_SAMPLES-1)));
d281 1
a281 1
      MATH_VEC_MUL_SCALAR(temp, step_y, ((TFLOAT)n/(TFLOAT)(UTIL_CAMERA_DOF_SAMPLES-1)));
d358 1
a358 1
  TFLOAT view_inv;
d445 1
a445 1
	TFLOAT alpha;
d449 4
a452 4
	((TFLOAT *)(td->res_buf))[res_ind + 0] = pixel.v[0];
	((TFLOAT *)(td->res_buf))[res_ind + 1] = pixel.v[1];
	((TFLOAT *)(td->res_buf))[res_ind + 2] = pixel.v[2];
	((TFLOAT *)(td->res_buf))[res_ind + 3] = alpha;
d489 1
a489 1
    *res_len = 4 * sizeof(TFLOAT) * work.size_x * work.size_y + sizeof(common_work_t);
@


1.24
log
@give adrt some distinctiveness in the header
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.23 2007/02/02 19:46:35 erikgreenwald Exp $
d90 1
a90 1
  if(camera->thread_num > 1)
d92 9
d128 4
d271 4
@


1.23
log
@finish changing all #defined symbols to uppercase...
@
text
@d2 1
a2 1
 * BRL-CAD
d32 1
a32 1
 * $Id: camera.c,v 1.22 2007/01/27 01:41:30 brlcad Exp $
@


1.22
log
@ws. lots and lots of ws.  see sh/ws.sh for details (cases 'abcdeg').
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.21 2007/01/23 01:13:22 brlcad Exp $
d104 1
a104 1
  tfloat	sfov, cfov, sdof, cdof, aspect, angle, mag;
d109 1
a109 1
  aspect = (tfloat)db->env.img_vw / (tfloat)db->env.img_vh;
d262 1
a262 1
      MATH_VEC_MUL_SCALAR(temp, step_x, ((tfloat)i/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
d264 1
a264 1
      MATH_VEC_MUL_SCALAR(temp, step_y, ((tfloat)n/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
d341 1
a341 1
  tfloat view_inv;
d428 1
a428 1
	tfloat alpha;
d432 4
a435 4
	((tfloat *)(td->res_buf))[res_ind + 0] = pixel.v[0];
	((tfloat *)(td->res_buf))[res_ind + 1] = pixel.v[1];
	((tfloat *)(td->res_buf))[res_ind + 2] = pixel.v[2];
	((tfloat *)(td->res_buf))[res_ind + 3] = alpha;
d472 1
a472 1
    *res_len = 4 * sizeof(tfloat) * work.size_x * work.size_y + sizeof(common_work_t);
@


1.21
log
@Sweeping license updates.  Documentation is fully relicensed to the BSD Documentation License (a minor variant of the FreeBSD Documentation License and BSD License).  All GPL code (mostly application code) is converted to the LGPL and now also specifically declares version 2.1, revoking the blank check to the FSF.  The intent of these sweeping changes are to simplify the licensing terms and increase overall flexibility of use, both externally (to users for their purposes) and internally (to allow application code to be migrated to libraries without creating GPL libraries).  As a collective work, BRL-CAD is now LGPL.
@
text
@d32 1
a32 1
 * $Id: camera.c,v 1.20 2007/01/21 00:51:05 brlcad Exp $
d382 1
a382 1
        MATH_VEC_SET(accum, 0, 0, 0);
d384 5
a388 5
        for(d = 0; d < td->camera->view_num; d++) {
          MATH_VEC_MUL_SCALAR(ray.dir, td->camera->view_list[d].step_y, v_scanline);
          MATH_VEC_ADD(ray.dir, ray.dir, td->camera->view_list[d].top_l);
          MATH_VEC_MUL_SCALAR(v1, td->camera->view_list[d].step_x, n);
          MATH_VEC_ADD(ray.dir, ray.dir, v1);
d390 1
a390 1
          MATH_VEC_SET(pixel, 0, 0, 0);
d392 3
a394 3
          ray.pos = td->camera->view_list[d].pos;
          ray.depth = 0;
          MATH_VEC_UNITIZE(ray.dir);
d396 2
a397 2
          /* Compute pixel value using this ray */
          td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
d399 2
a400 2
          MATH_VEC_ADD(accum, accum, pixel);
        }
d402 2
a403 2
        /* Find Mean value of all views */
        MATH_VEC_MUL_SCALAR(pixel, accum, view_inv);
d405 2
a406 2
        MATH_VEC_MUL_SCALAR(v2, td->camera->view_list[0].step_x, n);
        MATH_VEC_ADD(ray.dir, v1, v2);
d408 1
a408 1
        MATH_VEC_SET(pixel, 0, 0, 0);
d410 3
a412 3
        ray.pos = td->camera->view_list[0].pos;
        ray.depth = 0;
        MATH_VEC_UNITIZE(ray.dir);
d414 2
a415 2
        /* Compute pixel value using this ray */
        td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
d420 7
a426 7
        if(pixel.v[0] > 1) pixel.v[0] = 1;
        if(pixel.v[1] > 1) pixel.v[1] = 1;
        if(pixel.v[2] > 1) pixel.v[2] = 1;
        ((char *)(td->res_buf))[res_ind+0] = (unsigned char)(255 * pixel.v[0]);
        ((char *)(td->res_buf))[res_ind+1] = (unsigned char)(255 * pixel.v[1]);
        ((char *)(td->res_buf))[res_ind+2] = (unsigned char)(255 * pixel.v[2]);
        res_ind += 3;
d428 1
a428 1
        tfloat alpha;
d430 1
a430 1
        alpha = 1.0;
d432 4
a435 4
        ((tfloat *)(td->res_buf))[res_ind + 0] = pixel.v[0];
        ((tfloat *)(td->res_buf))[res_ind + 1] = pixel.v[1];
        ((tfloat *)(td->res_buf))[res_ind + 2] = pixel.v[2];
        ((tfloat *)(td->res_buf))[res_ind + 3] = alpha;
d437 1
a437 1
        res_ind += 4;
@


1.20
log
@standard header and footer cleanup
@
text
@d9 1
a9 2
 * as published by the Free Software Foundation; either version 2 of
 * the License, or (at your option) any later version.
d14 1
a14 1
 * Library General Public License for more details.
d32 1
a32 1
 * $Id: camera.c,v 1.19 2007/01/20 14:36:41 brlcad Exp $
@


1.19
log
@update copyright to 2007
@
text
@a1 3
 *
 * @@file camera.c
 *
d20 2
d33 1
a33 1
 * $Id: camera.c,v 1.18 2007/01/18 22:17:57 erikgreenwald Exp $
d500 10
@


1.18
log
@uppercase all #define symbols
@
text
@d7 1
a7 1
 * Copyright (c) 2002-2006 United States Government as represented by
d34 1
a34 1
 * $Id: camera.c,v 1.17 2006/01/18 06:46:12 brlcad Exp $
@


1.17
log
@update copyright to 2006
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.16 2005/10/30 21:58:57 brlcad Exp $
d123 2
a124 2
    math_vec_sub(fov_look, camera->focus, camera->pos);
    math_vec_unitize(fov_look);
d133 4
a136 4
    math_vec_dot(angle, fov_up, temp);
    math_vec_mul_scalar(temp, temp, angle);
    math_vec_sub(fov_up, fov_up, temp);
    math_vec_unitize(fov_up);
d139 1
a139 1
    math_vec_cross(fov_side, fov_up, fov_look);
d142 5
a146 5
    sfov = sin(-camera->tilt * math_pi * math_1div180);
    cfov = cos(-camera->tilt * math_pi * math_1div180);
    math_vec_mul_scalar(fov_up, fov_up, cfov);
    math_vec_mul_scalar(fov_side, fov_side, sfov);
    math_vec_add(fov_up, fov_up, fov_side);
d149 1
a149 1
    math_vec_cross(fov_side, fov_up, fov_look);
d152 2
a153 2
    sfov = sin(camera->fov*math_pi * math_1div180);
    cfov = cos(camera->fov*math_pi * math_1div180);
d169 3
a171 3
    math_vec_unitize(fov_topl);
    math_vec_unitize(fov_botl);
    math_vec_unitize(fov_topr);
d180 2
a181 2
    math_vec_sub(camera->view_list[0].step_x, fov_topr, fov_topl);
    math_vec_sub(camera->view_list[0].step_y, fov_botl, fov_topl);
d184 2
a185 2
    math_vec_mul_scalar(camera->view_list[0].step_x, camera->view_list[0].step_x, 1.0 / db->env.img_vw);
    math_vec_mul_scalar(camera->view_list[0].step_y, camera->view_list[0].step_y, 1.0 / db->env.img_vh);
d194 2
a195 2
  math_vec_sub(dof_look, camera->focus, camera->pos);
  math_vec_unitize(dof_look);
d204 4
a207 4
  math_vec_dot(angle, dof_up, temp);
  math_vec_mul_scalar(temp, temp, angle);
  math_vec_sub(dof_up, dof_up, temp);
  math_vec_unitize(dof_up);
d210 1
a210 1
  math_vec_cross(dof_side, dof_up, dof_look);
d213 5
a217 5
  sdof = sin(-camera->tilt * math_pi * math_1div180);
  cdof = cos(-camera->tilt * math_pi * math_1div180);
  math_vec_mul_scalar(dof_up, dof_up, cdof);
  math_vec_mul_scalar(dof_side, dof_side, sdof);
  math_vec_add(dof_up, dof_up, dof_side);
d220 1
a220 1
  math_vec_cross(dof_side, dof_up, dof_look);
d227 3
a229 3
  math_vec_sub(dof_look, camera->pos, camera->focus);
  math_vec_mag(mag, dof_look);
  math_vec_unitize(dof_look);
d233 2
a234 2
  sdof = sin(camera->dof*math_pi * math_1div180);
  cdof = cos(camera->dof*math_pi * math_1div180);
d250 3
a252 3
  math_vec_unitize(dof_topl);
  math_vec_unitize(dof_botl);
  math_vec_unitize(dof_topr);
d254 2
a255 2
  math_vec_sub(step_x, dof_topr, dof_topl);
  math_vec_sub(step_y, dof_botl, dof_topl);
d264 7
a270 7
      math_vec_mul_scalar(temp, step_x, ((tfloat)i/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
      math_vec_add(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, dof_topl, temp);
      math_vec_mul_scalar(temp, step_y, ((tfloat)n/(tfloat)(UTIL_CAMERA_DOF_SAMPLES-1)));
      math_vec_add(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, temp);
      math_vec_unitize(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos);
      math_vec_mul_scalar(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, mag);
      math_vec_add(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos, camera->focus);
d273 2
a274 2
      math_vec_sub(fov_look, camera->focus, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].pos);
      math_vec_unitize(fov_look);
d283 4
a286 4
      math_vec_dot(angle, fov_up, temp);
      math_vec_mul_scalar(temp, temp, angle);
      math_vec_sub(fov_up, fov_up, temp);
      math_vec_unitize(fov_up);
d289 1
a289 1
      math_vec_cross(fov_side, fov_up, fov_look);
d292 5
a296 5
      sfov = sin(-camera->tilt * math_pi * math_1div180);
      cfov = cos(-camera->tilt * math_pi * math_1div180);
      math_vec_mul_scalar(fov_up, fov_up, cfov);
      math_vec_mul_scalar(fov_side, fov_side, sfov);
      math_vec_add(fov_up, fov_up, fov_side);
d299 1
a299 1
      math_vec_cross(fov_side, fov_up, fov_look);
d302 2
a303 2
      sfov = sin(camera->fov*math_pi * math_1div180);
      cfov = cos(camera->fov*math_pi * math_1div180);
d319 3
a321 3
      math_vec_unitize(fov_topl);
      math_vec_unitize(fov_botl);
      math_vec_unitize(fov_topr);
d327 2
a328 2
      math_vec_sub(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, fov_topr, fov_topl);
      math_vec_sub(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, fov_botl, fov_topl);
d331 2
a332 2
      math_vec_mul_scalar(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_x, 1.0 / db->env.img_vw);
      math_vec_mul_scalar(camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, camera->view_list[i*UTIL_CAMERA_DOF_SAMPLES+n].step_y, 1.0 / db->env.img_vh);
d374 2
a375 2
      math_vec_mul_scalar(v1, td->camera->view_list[0].step_y, v_scanline);
      math_vec_add(v1, v1, td->camera->view_list[0].top_l);
d384 1
a384 1
        math_vec_set(accum, 0, 0, 0);
d387 4
a390 4
          math_vec_mul_scalar(ray.dir, td->camera->view_list[d].step_y, v_scanline);
          math_vec_add(ray.dir, ray.dir, td->camera->view_list[d].top_l);
          math_vec_mul_scalar(v1, td->camera->view_list[d].step_x, n);
          math_vec_add(ray.dir, ray.dir, v1);
d392 1
a392 1
          math_vec_set(pixel, 0, 0, 0);
d396 1
a396 1
          math_vec_unitize(ray.dir);
d401 1
a401 1
          math_vec_add(accum, accum, pixel);
d405 1
a405 1
        math_vec_mul_scalar(pixel, accum, view_inv);
d407 2
a408 2
        math_vec_mul_scalar(v2, td->camera->view_list[0].step_x, n);
        math_vec_add(ray.dir, v1, v2);
d410 1
a410 1
        math_vec_set(pixel, 0, 0, 0);
d414 1
a414 1
        math_vec_unitize(ray.dir);
@


1.16
log
@remove C++-style // comments as there's no assumption of c99 compiler compliance yet, only c89 (mostly aix compiler though other old compilers too)
@
text
@d7 1
a7 1
 * Copyright (C) 2002-2005 United States Government as represented by
d34 1
a34 1
 * $Id: camera.c,v 1.15 2005/10/23 04:44:28 brlcad Exp $
@


1.15
log
@trailing ws
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.14 2005/09/21 16:16:16 twingy Exp $
d351 1
a351 1
//  for(i = td->work.orig_y; i < td->work.orig_y + td->work.size_y; i++) {	/* row, vertical */
@


1.14
log
@reverted
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.12 2005/09/20 19:27:55 twingy Exp $
d64 1
a64 1
int get_nprocs() {   
d73 1
a73 1
}  
@


1.13
log
@librender is now libvis, render method terminology becomes visualization method or vis
method for short.
@
text
@d399 1
a399 1
          td->db->env.vis.work(&td->db->env.vis, td->tie, &ray, &pixel);
d417 1
a417 1
        td->db->env.vis.work(&td->db->env.vis, td->tie, &ray, &pixel);
@


1.12
log
@removed expensive memcpy from camera ray generation, 1.4% performance boost.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.11 2005/09/20 19:05:35 twingy Exp $
d399 1
a399 1
          td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
d417 1
a417 1
        td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
@


1.11
log
@optimized non depth of field rendering, performance is 1% faster.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.10 2005/09/12 18:13:47 twingy Exp $
d368 1
a368 1
      res_ind = 4*sizeof(tfloat)*scanline*td->work.size_x;
a421 2
        unsigned char rgb_24[3];

d425 3
a427 6
        rgb_24[0] = (unsigned char)(255 * pixel.v[0]);
        rgb_24[1] = (unsigned char)(255 * pixel.v[1]);
        rgb_24[2] = (unsigned char)(255 * pixel.v[2]);

        /* Pack pixel into result buffer */
        memcpy(&((char *)(td->res_buf))[res_ind], rgb_24, 3);
d430 3
a432 1
        tfloat rgb_128[4];
d434 4
a437 4
        rgb_128[0] = pixel.v[0];
        rgb_128[1] = pixel.v[1];
        rgb_128[2] = pixel.v[2];
        rgb_128[3] = 1.0;
d439 1
a439 2
        memcpy(&((char *)(td->res_buf))[res_ind], rgb_128, 4*sizeof(tfloat));
        res_ind += 4*sizeof(tfloat);
@


1.10
log
@camera uses threads more efficiently.
isst master locks the frames down so observer doesn't get mid-render frames.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.9 2005/09/10 19:16:29 twingy Exp $
d341 1
a341 1
  TIE_3 pixel, accum, v;
d372 12
a383 2
      /* scanline, horizontal, each pixel */
      for(n = td->work.orig_x; n < td->work.orig_x + td->work.size_x; n++) {
a385 1
        /* depth of view samples */
d387 4
a390 4
          math_vec_mul_scalar(v, td->camera->view_list[d].step_x, n);
          math_vec_add(ray.dir, td->camera->view_list[d].top_l, v);
          math_vec_mul_scalar(v, td->camera->view_list[d].step_y, v_scanline);
          math_vec_add(ray.dir, ray.dir, v);
d406 13
a419 2
        if(td->work.format == COMMON_BIT_DEPTH_24) {
          unsigned char rgb_24[3];
d421 2
a422 17
          if(pixel.v[0] > 1) pixel.v[0] = 1;
          if(pixel.v[1] > 1) pixel.v[1] = 1;
          if(pixel.v[2] > 1) pixel.v[2] = 1;
          rgb_24[0] = (unsigned char)(255 * pixel.v[0]);
          rgb_24[1] = (unsigned char)(255 * pixel.v[1]);
          rgb_24[2] = (unsigned char)(255 * pixel.v[2]);

          /* Pack pixel into result buffer */
          memcpy(&((char *)(td->res_buf))[res_ind], rgb_24, 3);
          res_ind += 3;
        } else if(td->work.format == COMMON_BIT_DEPTH_128) {
          tfloat rgb_128[4];

          rgb_128[0] = pixel.v[0];
          rgb_128[1] = pixel.v[1];
          rgb_128[2] = pixel.v[2];
          rgb_128[3] = 1.0;
d424 21
a444 3
          memcpy(&((char *)(td->res_buf))[res_ind], rgb_128, 4*sizeof(tfloat));
          res_ind += 4*sizeof(tfloat);
        }
d447 1
a447 1
      }
@


1.9
log
@stuff to fix 32/64 communication
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.8 2005/09/09 22:06:26 twingy Exp $
d339 5
a343 5
  util_camera_thread_data_t	*td;
  int				d, i, n, res_ind, compute;
  TIE_3				pixel, accum, v;
  tie_ray_t			ray;
  tfloat			view_inv;
d351 2
a352 1
  for(i = td->work.orig_y; i < td->work.orig_y + td->work.size_y; i++) {	/* row, vertical */
d355 7
a361 2
    compute = td->scan_map[i-td->work.orig_y];
    td->scan_map[i-td->work.orig_y] = 0;
d364 11
a374 2
    if(compute) {
      for(n = td->work.orig_x; n < td->work.orig_x + td->work.size_x; n++) {	/* scanline, horizontal, each pixel */
d376 2
a377 2
        accum.v[0] = accum.v[1] = accum.v[2] = 0;
        for(d = 0; d < td->camera->view_num; d++) {	/* depth of view samples */
d380 1
a380 1
          math_vec_mul_scalar(v, td->camera->view_list[d].step_y, i);
a424 7
    } else {
      if(td->work.format == COMMON_BIT_DEPTH_24) {
        res_ind += 3*td->work.size_x;
      } else if(td->work.format == COMMON_BIT_DEPTH_128) {
        res_ind += 4*sizeof(tfloat)*td->work.size_x;
      }
    }
d436 1
a436 1
  int i;
a451 5
  /* allocate memory for scanmap */
  scan_map = (unsigned char *)malloc(work.size_y);
  memset(scan_map, 1, work.size_y);


d466 2
a467 1
  td.scan_map = scan_map;
a479 1
  free(scan_map);
@


1.8
log
@fixed 64/32 bit network communications bug in tienet.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.7 2005/08/15 03:45:25 twingy Exp $
d82 1
a82 5
void	util_camera_init(util_camera_t *camera, int threads);
void	util_camera_free(util_camera_t *camera);
void	util_camera_prep(util_camera_t *camera, common_db_t *db);
void*	util_camera_render_thread(void *ptr);
void	util_camera_render(util_camera_t *camera, common_db_t *db, tie_t *tie, void *data, int size, void **res_buf, int *res_len);
d423 1
a423 1
void util_camera_render(util_camera_t *camera, common_db_t *db, tie_t *tie, void *data, int size, void **res_buf, int *res_len) {
a477 2

  printf("res_len: %d\n", *res_len);
@


1.7
log
@adding local benchmark utility minus networking stuff to do benchmarking with TIE.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.6 2005/07/11 22:33:45 brlcad Exp $
d447 1
d482 2
@


1.7.4.1
log
@merge changes from HEAD aka rel-7-6-4 to the rel-7-6-branch just in case someone peeks a gander or tries to continue/build the branch
@
text
@d34 1
a34 1
 * $Id$
d64 1
a64 1
int get_nprocs() {
d73 1
a73 1
}
d82 5
a86 1
void* util_camera_render_thread(void *ptr);
d343 5
a347 5
  util_camera_thread_data_t *td;
  int d, n, res_ind, scanline, v_scanline;
  TIE_3 pixel, accum, v1, v2;
  tie_ray_t ray;
  tfloat view_inv;
d355 1
a355 2
  /*  for(i = td->work.orig_y; i < td->work.orig_y + td->work.size_y; i++) { */	/* row, vertical */
  while(1) {
d358 2
a359 7
    if(*td->scanline == td->work.size_y) {
      pthread_mutex_unlock(&td->mut);
      return(0);
    } else {
      scanline = *td->scanline;
      (*td->scanline)++;
    }
d362 2
a363 6
    v_scanline = scanline + td->work.orig_y;
    if(td->work.format == COMMON_BIT_DEPTH_24) {
      res_ind = 3*scanline*td->work.size_x;
    } else if(td->work.format == COMMON_BIT_DEPTH_128) {
      res_ind = 4*scanline*td->work.size_x;
    }
d365 6
a370 20

    /* optimization if there is no depth of field being applied */
    if(td->camera->view_num == 1) {
      math_vec_mul_scalar(v1, td->camera->view_list[0].step_y, v_scanline);
      math_vec_add(v1, v1, td->camera->view_list[0].top_l);
    }


    /* scanline, horizontal, each pixel */
    for(n = td->work.orig_x; n < td->work.orig_x + td->work.size_x; n++) {

      /* depth of view samples */
      if(td->camera->view_num > 1) {
        math_vec_set(accum, 0, 0, 0);

        for(d = 0; d < td->camera->view_num; d++) {
          math_vec_mul_scalar(ray.dir, td->camera->view_list[d].step_y, v_scanline);
          math_vec_add(ray.dir, ray.dir, td->camera->view_list[d].top_l);
          math_vec_mul_scalar(v1, td->camera->view_list[d].step_x, n);
          math_vec_add(ray.dir, ray.dir, v1);
a385 9
      } else {
        math_vec_mul_scalar(v2, td->camera->view_list[0].step_x, n);
        math_vec_add(ray.dir, v1, v2);

        math_vec_set(pixel, 0, 0, 0);

        ray.pos = td->camera->view_list[0].pos;
        ray.depth = 0;
        math_vec_unitize(ray.dir);
d387 20
a406 3
        /* Compute pixel value using this ray */
        td->db->env.render.work(&td->db->env.render, td->tie, &ray, &pixel);
      }
d408 4
d413 2
d416 1
a416 7
        if(pixel.v[0] > 1) pixel.v[0] = 1;
        if(pixel.v[1] > 1) pixel.v[1] = 1;
        if(pixel.v[2] > 1) pixel.v[2] = 1;
        ((char *)(td->res_buf))[res_ind+0] = (unsigned char)(255 * pixel.v[0]);
        ((char *)(td->res_buf))[res_ind+1] = (unsigned char)(255 * pixel.v[1]);
        ((char *)(td->res_buf))[res_ind+2] = (unsigned char)(255 * pixel.v[2]);
        res_ind += 3;
d418 1
a418 10
        tfloat alpha;

        alpha = 1.0;

        ((tfloat *)(td->res_buf))[res_ind + 0] = pixel.v[0];
        ((tfloat *)(td->res_buf))[res_ind + 1] = pixel.v[1];
        ((tfloat *)(td->res_buf))[res_ind + 2] = pixel.v[2];
        ((tfloat *)(td->res_buf))[res_ind + 3] = alpha;

        res_ind += 4;
a419 2
/*          printf("Pixel: [%d, %d, %d]\n", rgb[0], rgb[1], rgb[2]); */

d427 1
a427 1
void util_camera_render(util_camera_t *camera, common_db_t *db, tie_t *tie, void *data, unsigned int size, void **res_buf, unsigned int *res_len) {
d432 1
a432 1
  unsigned int i, scanline;
d447 4
d466 1
a466 2
  scanline = 0;
  td.scanline = &scanline;
d479 1
@


1.6
log
@ws
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.5 2005/07/02 19:54:59 twingy Exp $
d372 1
a372 3
          pixel.v[0] = 0;
          pixel.v[1] = 0;
          pixel.v[2] = 0;
@


1.5
log
@fixed memory leak in camera utility.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.4 2005/06/21 05:36:29 twingy Exp $
d50 1
a50 1
#include <sys/sysinfo.h>
d52 1
a52 1
#include <sys/sysctl.h>
@


1.4
log
@licensing stuff.
@
text
@d34 1
a34 1
 * $Id: camera.c,v 1.3 2005/06/18 01:30:04 twingy Exp $
d117 3
@


1.3
log
@Added licensing info to libutil files.
@
text
@d2 3
a22 3
 */
/** @@file camera.c
 *                     C A M E R A . C
d24 2
a25 1
 *  Utilities Library - Camera
d34 1
a34 1
 * $Id: camera.c,v 1.2 2005/06/18 01:09:31 twingy Exp $
@


1.2
log
@use brlcad_config.h instead of config.h
@
text
@d1 35
@


1.1
log
@Welcome ADRT
@
text
@d9 1
a9 1
#include "config.h"
@

